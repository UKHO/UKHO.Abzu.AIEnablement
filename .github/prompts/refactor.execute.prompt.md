# Refactor Execution Mode

Execute a provided Refactoring Implementation Plan while preserving behavior and improving code quality.

Inputs:
- The Implementation Plan generated by refactor.plan.prompt.md (Work Item / Task / Step structure)
- Project build/test context and environment

Objectives:
- Preserve existing behavior and public contracts unless explicitly approved
- Apply SOLID principles (SRP, OCP, LSP, ISP, DIP) during changes
- Improve readability, maintainability, testability, and modularity
- Reduce duplication, complexity, and technical debt
- Keep changes small, incremental, and well-tested

Pre-flight (once per execution session):
1) Create a feature branch from Main
2) Build the solution; resolve build issues
3) Run all tests; confirm baseline pass/fail
4) Generate coverage report and capture baseline
5) Enable analyzers/linters; note existing warnings

Execution Loop (by Area/Component -> Work Item -> Tasks -> Steps):
For each Area/Component in the plan:
- Announce the Area and list its Work Items
- Process Work Items sequentially; do not skip dependencies

For each Work Item:
- Restate Goal, SOLID Focus, Risk, Success Criteria, Coverage Target, Metrics
- If required, strengthen tests BEFORE refactoring:
  - Add/extend tests to cover critical behaviors and edge cases for this Work Item
  - Aim for coverage target on impacted files/paths
- Execute Tasks in order. For each Task:
  - Execute each Step:
    - Apply the smallest change necessary (e.g., rename, extract method/class, move to interface, split interface, introduce value object, apply strategy/policy, inject dependency)
    - After each Step:
      - Build the solution
      - Run tests
      - Verify no new analyzer warnings
      - Apply the SOLID Checklist to the changed code
      - If a check fails, revert/adjust and re-run
- When all Steps in the Work Item are complete:
  - Re-run all tests and coverage for impacted areas
  - Validate Success Criteria, Coverage Target, and Metrics
  - Commit changes
    - Use messages like: `refactor([area]): [short description]` and `test([area]): [tests added/updated]`
  - Optionally push and open a PR draft for early feedback

Recommended Checks (per Task/Step and at Work Item completion):
- Build succeeds; all tests pass
- Coverage for changed areas maintained or improved; meets target
- Analyzer/linters show no new warnings
- SOLID Checklist satisfied:
  - SRP: class/method has one reason to change
  - OCP: new behavior can be added via extension points
  - LSP: subtypes honor base contracts; no broken substitution
  - ISP: consumers depend only on what they use
  - DIP: high-level depends on abstractions; DI used appropriately

Behavioral Safety Rules:
- Do not change external behavior or public APIs unless explicitly called out in the plan
- If behavior must change, isolate behind a feature flag and add tests to pin new behavior
- Prefer composition over inheritance; avoid brittle hierarchies

Debugging & Recovery:
- If a Step fails (build/test/metrics), minimize the change scope, revert as needed, and iterate
- Update the plan with any discovered constraints or follow-ups

Updating the Plan:
- After completing a Step: mark it as complete in the plan
- After completing a Task: summarize changes, tests, and coverage deltas
- After completing a Work Item: check off the Work Item and note metrics improvements and remaining risks

Pull Request Guidelines:
- Prepare a clear PR description:
  - Motivation and intended benefits
  - Summary of changes
  - SOLID improvements achieved
  - Test results and coverage summary
  - Risk assessment and rollback plan
- Keep commits small and logically grouped (tests vs refactors as appropriate)

Post-Execution Finalization:
- Re-run full test suite and coverage
- Ensure no TODOs/commented-out code remain
- Ensure documentation and comments reflect the current design
- Prepare follow-up Work Items if new opportunities emerged

Command Examples (.NET):
- Build: `dotnet build`
- Test: `dotnet test`
- Coverage: `dotnet test --collect:"XPlat Code Coverage"`
- Format/Analyze: `dotnet format` and Roslyn analyzers
- Optional: BenchmarkDotNet for validating performance on hot paths

Output & Reporting:
- For each Work Item, end with:
  - "Refactor Work Item X Complete. Here's what I did and why:" followed by a concise explanation
  - "User instructions: Please do the following" for any manual/environment steps
- Maintain a running changelog of completed Work Items and remaining tasks

Operating Notes:
- Execute one Work Item at a time; keep changes reviewable
- Respect dependency order defined in the plan
- Ask for clarification if the plan is ambiguous or insufficient
